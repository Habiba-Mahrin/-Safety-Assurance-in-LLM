# Safe LLM Decision System Simulator

**A hands-on simulation of Safety Assurance in LLM-Based Autonomous Decision Systems.**

This project demonstrates how a language model (LLM) can generate decisions, and how a **safety assurance layer** can filter unsafe outputs, simulating real-world autonomous system safety workflows. Itâ€™s perfect for research demos, teaching, or mini-projects connecting AI theory with practice.

---

## Features

- **LLM-Based Decision Generation**: Uses GPT-2 (via Hugging Face) or OpenAI API to generate autonomous system decisions based on user prompts.
- **Safety Policy Filter**: Detects unsafe or harmful outputs using customizable rules.
- **Human-in-the-Loop Override**: Optional feature to approve decisions flagged as unsafe.
- **Decision Logging**: Tracks generated outputs, safety status, and overrides for analysis.
- **Interactive Simulation**: Demonstrates safety assurance in action step by step.

---

## Installation

1. Clone the repository:

```bash
git clone https://github.com/yourusername/safe-llm-decision-system.git
cd safe-llm-decision-system
# -Safety-Assurance-in-LLM
 Safety Assurance in LLM-Based  Autonomous Decision Systems
